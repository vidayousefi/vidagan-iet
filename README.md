# vidaGAN

vidaGAN is a deep learning project focused on Generative Adversarial Networks (GANs) for image and video synthesis. This repository contains code, models, and documentation to help you train and evaluate GANs for various generative tasks.

# Abstract

A recent approach to image steganography is to use deep learning. Mainly, convolutional neural networks can extract complex features and use them as patterns to combine hidden messages and images. Also, by using generative adversarial networks, it is possible to generate realistic and high-quality stego images without any noticeable artifacts. Previous methods suffered from challenges such as simple architecture, low network accuracy, imbalance between capacity and transparency, vanishing gradients, and low capacity. This study introduces a steganography framework named VidaGAN that utilizes deep learning techniques. The network being proposed is made up of three components: an encoder, a decoder, and a critic, and introduces a novel architecture and several innovations to address some of the unresolved challenges mentioned above. This study introduces a novel method for embedding any type of binary data into images using generative adversarial networks, enabling us to enhance the visual appeal of images generated by the specified model. This neural network called VarIable aDAptive GAN (VidaGAN) achieved state-of-the-art status by reaching a hiding capacity of 3.9 bits per pixel in the DIV2K dataset. Furthermore, examination by the StegExpose steganalysis tool shows an AUC of 0.6, a suitable threshold for transparency.

## Features

- Modular GAN architecture for images and videos
- Training and evaluation scripts
- Preprocessing utilities
- Sample datasets and results

## Installation

```bash
git clone https://github.com/mrtkhosravi/VidaGAN.git
cd vidaGAN
pip install -r requirements.txt
```

## Usage

Train a GAN model:
```bash
python train.py --train_dataset=PATH_TO_TRAIN_IMAGES --val_dataset=PATH_TO_VAL_IMAGES
```

Additional Parameters:

 --epochs,          default=16

 --data_depth,      default=6
 
 --batch_size,      default=4
 

Generate random stego images:
```bash
python inference.py --source_path=COVER_IMAGE_DIR --dest_path=GENERATED_STEGO_DIR --model_path=PATH_TO_TRAIED_MODEL --data_depth=DATA_DEPTH_OF_TRAINED_MODEL
```

## License

This project is licensed under the MIT License.
